{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31012,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Smart Auto Assist","metadata":{}},{"cell_type":"markdown","source":"**Documentation or Blog:** -- https://medium.com/@argowtham3030/smart-auto-assist-55b2f5cb66f1\n\n**Video Explanation** -- https://youtu.be/TfZaIMW6x6I","metadata":{}},{"cell_type":"markdown","source":"**WorkFlow**\n\n![](https://raw.githubusercontent.com/argowthamkumar/kaggle/refs/heads/main/capstone/images/flowchart.jpg)","metadata":{}},{"cell_type":"markdown","source":"**Install Required Libraries**","metadata":{}},{"cell_type":"code","source":"# Uninstall packages from Kaggle base image that are not needed.\n!pip uninstall -qy jupyterlab jupyterlab-lsp\n# Install the google-genai SDK for this codelab.\n!pip install -qU 'google-genai==1.7.0' \n\n# Install necessary libraries for Image Processing, RAG, Grounding, Agent\n!pip install -q -U langchain langchain-core langchain-community langchain-google-genai langgraph google-generativeai chromadb pypdf python-dotenv Pillow requests","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:13:54.537639Z","iopub.execute_input":"2025-04-18T19:13:54.538040Z","iopub.status.idle":"2025-04-18T19:15:04.579293Z","shell.execute_reply.started":"2025-04-18T19:13:54.538007Z","shell.execute_reply":"2025-04-18T19:15:04.578072Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m144.7/144.7 kB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m100.9/100.9 kB\u001b[0m \u001b[31m5.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.3/67.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m43.5/43.5 kB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.0/1.0 MB\u001b[0m \u001b[31m22.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m433.9/433.9 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.5/2.5 MB\u001b[0m \u001b[31m58.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m155.4/155.4 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m145.2/145.2 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m59.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m94.9/94.9 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.6/4.6 MB\u001b[0m \u001b[31m74.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m284.2/284.2 kB\u001b[0m \u001b[31m12.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m53.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.0/42.0 kB\u001b[0m \u001b[31m1.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.2/47.2 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.6/101.6 kB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.0/16.0 MB\u001b[0m \u001b[31m67.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m52.5/52.5 kB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m149.7/149.7 kB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.0/64.0 kB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m110.5/110.5 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.1/89.1 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.4/62.4 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m459.8/459.8 kB\u001b[0m \u001b[31m20.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m223.6/223.6 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.5/71.5 kB\u001b[0m \u001b[31m3.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.0/4.0 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m454.8/454.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m4.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for pypika (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndopamine-rl 4.1.2 requires gymnasium>=1.0.0, but you have gymnasium 0.29.0 which is incompatible.\nbigframes 1.36.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.5 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"from google import genai\nfrom google.genai import types\n\nfrom IPython.display import Markdown, HTML, display\n\ngenai.__version__","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:04.581382Z","iopub.execute_input":"2025-04-18T19:15:04.581786Z","iopub.status.idle":"2025-04-18T19:15:06.298764Z","shell.execute_reply.started":"2025-04-18T19:15:04.581744Z","shell.execute_reply":"2025-04-18T19:15:06.297808Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"'1.7.0'"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from kaggle_secrets import UserSecretsClient\n\nGOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n\nclient = genai.Client(api_key=GOOGLE_API_KEY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:06.299708Z","iopub.execute_input":"2025-04-18T19:15:06.300107Z","iopub.status.idle":"2025-04-18T19:15:06.910773Z","shell.execute_reply.started":"2025-04-18T19:15:06.300084Z","shell.execute_reply":"2025-04-18T19:15:06.909734Z"}},"outputs":[],"execution_count":3},{"cell_type":"markdown","source":"# Image Analysis code","metadata":{}},{"cell_type":"code","source":"# Import libraries\nimport requests\nimport PIL\n#from PIL import Image\nimport io\nimport google.generativeai as genai\n\n# Define function to load image from URL\ndef load_image_from_url(image_url):\n    response = requests.get(image_url, stream=True)\n    response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n    image = PIL.Image.open(io.BytesIO(response.content)).convert(\"RGB\")\n    return image\n\n# Configure the Gemini API\n#GOOGLE_API_KEY = \"YOUR_API_KEY\" # Replace with your actual API key\ngenai.configure(api_key=GOOGLE_API_KEY)\nmodel = genai.GenerativeModel('gemini-2.0-flash')\n\n# Update the process_image function\ndef process_image(image_url):\n    \"\"\"\n    Processes an image URL, describes its contents using the Gemini model, and returns the description.\n    \"\"\"\n    try:\n        # Load the image\n        image = load_image_from_url(image_url)\n\n        # Prepare the prompt for the Gemini model\n        prompt = \"Describe the contents of this image and if the image contains warning lights, indicate the Severity of warning in bold\"\n\n        # Generate content using the Gemini model\n        response = model.generate_content([prompt, image])\n\n        # Return the description from the Gemini model's response\n        return response.text\n    except Exception as e:\n        return f\"Error processing image: {e}\"\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:06.913181Z","iopub.execute_input":"2025-04-18T19:15:06.913828Z","iopub.status.idle":"2025-04-18T19:15:09.027027Z","shell.execute_reply.started":"2025-04-18T19:15:06.913795Z","shell.execute_reply":"2025-04-18T19:15:09.025957Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"#process_image(\"https://raw.githubusercontent.com/argowthamkumar/kaggle/refs/heads/main/capstone/images/low_fuel.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:09.028815Z","iopub.execute_input":"2025-04-18T19:15:09.029477Z","iopub.status.idle":"2025-04-18T19:15:09.034112Z","shell.execute_reply.started":"2025-04-18T19:15:09.029448Z","shell.execute_reply":"2025-04-18T19:15:09.033015Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Retrieval augmented generation (RAG)\n\n* Load PDF from URL","metadata":{}},{"cell_type":"code","source":"import os\nimport google.generativeai as genai\nfrom google.colab import userdata\n\nimport requests\nimport tempfile\n\n# Configure the Gemini API\ngenai.configure(api_key=GOOGLE_API_KEY)\n\nEMBEDDING_MODEL = \"models/embedding-001\"\nGENERATION_MODEL = \"gemini-1.5-flash\" \n\n# --- Configuration ---\n# We need the URL to the RAW PDF file content\nraw_pdf_url = \"https://raw.githubusercontent.com/argowthamkumar/kaggle/main/capstone/manual.pdf\" \n\nprint(f\"Attempting to download PDF from: {raw_pdf_url}\")\n\n# --- Download the PDF ---\ndownloaded_pdf_path = None # Initialize path variable\ntemp_pdf_file = None      # Initialize temp file object variable\n\ntry:\n    response = requests.get(raw_pdf_url, stream=True)\n    response.raise_for_status() # Raise an exception for bad status codes (4xx or 5xx)\n\n    # Create a temporary file to store the PDF content\n    # delete=False is important because PyPDFLoader needs to open the file by path later\n    # suffix=\".pdf\" helps identify the file type, though not strictly necessary for PyPDFLoader\n    temp_pdf_file = tempfile.NamedTemporaryFile(delete=False, suffix=\".pdf\")\n    with temp_pdf_file as f:\n        for chunk in response.iter_content(chunk_size=8192):\n            f.write(chunk)\n        downloaded_pdf_path = temp_pdf_file.name # Get the path to the temporary file\n    print(f\"PDF successfully downloaded and saved to temporary file: {downloaded_pdf_path}\")\n\nexcept requests.exceptions.RequestException as e:\n    print(f\"Error downloading PDF: {e}\")\n    # Clean up the temporary file if it was created but download failed mid-way\n    if downloaded_pdf_path and os.path.exists(downloaded_pdf_path):\n        os.remove(downloaded_pdf_path)\n    raise # Re-raise the exception to stop execution\n\nexcept Exception as e:\n    # Catch any other potential errors during file handling\n    print(f\"An error occurred: {e}\")\n    if downloaded_pdf_path and os.path.exists(downloaded_pdf_path):\n        os.remove(downloaded_pdf_path)\n    raise\n\n# --- Check if download path is set ---\nif not downloaded_pdf_path:\n     raise FileNotFoundError(\"PDF download failed or temporary file path was not set.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:09.035239Z","iopub.execute_input":"2025-04-18T19:15:09.035625Z","iopub.status.idle":"2025-04-18T19:15:09.795708Z","shell.execute_reply.started":"2025-04-18T19:15:09.035589Z","shell.execute_reply":"2025-04-18T19:15:09.794761Z"}},"outputs":[{"name":"stdout","text":"Attempting to download PDF from: https://raw.githubusercontent.com/argowthamkumar/kaggle/main/capstone/manual.pdf\nPDF successfully downloaded and saved to temporary file: /tmp/tmpbj_d4atu.pdf\n","output_type":"stream"}],"execution_count":6},{"cell_type":"markdown","source":"**Text Splitter**","metadata":{}},{"cell_type":"code","source":"\n# Load and Process the PDF\nfrom langchain_community.document_loaders import PyPDFLoader\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\n\n# Ensure the downloaded_pdf_path exists from the previous cell\nif 'downloaded_pdf_path' not in locals() or not downloaded_pdf_path or not os.path.exists(downloaded_pdf_path):\n     raise NameError(\"Variable 'downloaded_pdf_path' is not defined or the file doesn't exist. \"\n                     \"Make sure Cell 3 ran successfully.\")\n\nprint(f\"Loading PDF from temporary file: {downloaded_pdf_path}\")\nloader = PyPDFLoader(downloaded_pdf_path) # Use the temporary file path\n\npages = []\ntry:\n    # Load the PDF pages into LangChain Documents\n    pages = loader.load()\n    print(f\"Loaded {len(pages)} pages from the PDF.\")\nfinally:\n    # --- Clean up the temporary file ---\n    # It's crucial to delete the temp file after PyPDFLoader is done with it.\n    print(f\"Cleaning up temporary file: {downloaded_pdf_path}\")\n    if os.path.exists(downloaded_pdf_path):\n        os.remove(downloaded_pdf_path)\n        print(\"Temporary file removed.\")\n    else:\n        print(\"Temporary file not found (already removed or error occurred).\")\n    # Optional: Clear the variable to prevent accidental reuse\n    # del downloaded_pdf_path\n\n\n# --- Split documents into smaller chunks ---\nif not pages:\n     print(\"Warning: No pages were loaded from the PDF. Splitting step will be skipped.\")\n     chunks = []\nelse:\n    text_splitter = RecursiveCharacterTextSplitter(\n        chunk_size=1000,  # Maximum size of each chunk (in characters)\n        chunk_overlap=100, # Number of characters to overlap between chunks\n        length_function=len,\n        add_start_index=True, # Adds the start index of the chunk in the original document\n    )\n\n    # Split the documents loaded from the PDF\n    chunks = text_splitter.split_documents(pages)\n    print(f\"Split the document into {len(chunks)} chunks.\")\n   ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:09.796894Z","iopub.execute_input":"2025-04-18T19:15:09.797241Z","iopub.status.idle":"2025-04-18T19:15:17.534476Z","shell.execute_reply.started":"2025-04-18T19:15:09.797208Z","shell.execute_reply":"2025-04-18T19:15:17.533577Z"}},"outputs":[{"name":"stdout","text":"Loading PDF from temporary file: /tmp/tmpbj_d4atu.pdf\nLoaded 408 pages from the PDF.\nCleaning up temporary file: /tmp/tmpbj_d4atu.pdf\nTemporary file removed.\nSplit the document into 1036 chunks.\n","output_type":"stream"}],"execution_count":7},{"cell_type":"markdown","source":"# Embedding","metadata":{}},{"cell_type":"code","source":"#Initialize Embeddings Model\nfrom langchain_google_genai import GoogleGenerativeAIEmbeddings\n\n# Create an instance of the Gemini Embedding model\nembeddings = GoogleGenerativeAIEmbeddings(\n    model=EMBEDDING_MODEL,\n    task_type=\"retrieval_document\",\n    google_api_key=GOOGLE_API_KEY \n)\n# task_type can be: retrieval_query, retrieval_document, semantic_similarity, classification, clustering\n\nprint(\"Gemini Embeddings model initialized.\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:17.535376Z","iopub.execute_input":"2025-04-18T19:15:17.535842Z","iopub.status.idle":"2025-04-18T19:15:17.802148Z","shell.execute_reply.started":"2025-04-18T19:15:17.535809Z","shell.execute_reply":"2025-04-18T19:15:17.801244Z"}},"outputs":[{"name":"stdout","text":"Gemini Embeddings model initialized.\n","output_type":"stream"}],"execution_count":8},{"cell_type":"markdown","source":"# Vector Store  Chroma DB","metadata":{}},{"cell_type":"code","source":"\n# Setup ChromaDB Vector Store\nfrom langchain_community.vectorstores import Chroma\n\n# --- ChromaDB Configuration ---\nCHROMA_PATH = \"chroma_db_pdf\" # Directory to store ChromaDB data\nCOLLECTION_NAME = \"pdf_knowledge_base\" # Name of the collection within ChromaDB\n\nprint(f\"Setting up ChromaDB persistence directory: {CHROMA_PATH}\")\nprint(f\"Using collection name: {COLLECTION_NAME}\")\n\n# --- Create or Load the Vector Store ---\n# This will create the directory if it doesn't exist and load the data if it does.\n# It embeds the chunks and stores them in ChromaDB.\n# This step can take some time depending on the number of chunks and API limits.\nprint(\"Creating/loading ChromaDB vector store and embedding chunks...\")\ntry:\n    vectorstore = Chroma.from_documents(\n        documents=chunks,\n        embedding=embeddings,\n        persist_directory=CHROMA_PATH,\n        collection_name=COLLECTION_NAME\n    )\n    print(\"Vector store created/loaded successfully.\")\n    # Explicitly persist changes (good practice, though often handled by from_documents)\n    vectorstore.persist()\n    print(\"Vector store persisted.\")\n    # Check the number of items in the store\n    print(f\"Number of vectors in store: {vectorstore._collection.count()}\")\n\nexcept Exception as e:\n    print(f\"\\nError during vector store creation/embedding: {e}\")\n    print(\"Potential issues:\")\n    print(\"- API key limits reached (check your quota in Google Cloud Console).\")\n    print(\"- Network connectivity issues.\")\n    print(\"- Invalid API key or API not enabled.\")\n    # Depending on the error, you might need to retry or troubleshoot API access.\n    # For rate limit errors, you might need to add delays between embedding calls (more complex setup).\n    raise # Re-raise the exception to stop execution if embedding fails critically\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:17.803293Z","iopub.execute_input":"2025-04-18T19:15:17.803733Z","iopub.status.idle":"2025-04-18T19:15:36.172743Z","shell.execute_reply.started":"2025-04-18T19:15:17.803704Z","shell.execute_reply":"2025-04-18T19:15:36.171796Z"}},"outputs":[{"name":"stdout","text":"Setting up ChromaDB persistence directory: chroma_db_pdf\nUsing collection name: pdf_knowledge_base\nCreating/loading ChromaDB vector store and embedding chunks...\nVector store created/loaded successfully.\nVector store persisted.\nNumber of vectors in store: 1036\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_31/723472596.py:25: LangChainDeprecationWarning: Since Chroma 0.4.x the manual persistence method is no longer supported as docs are automatically persisted.\n  vectorstore.persist()\n","output_type":"stream"}],"execution_count":9},{"cell_type":"markdown","source":"**Model for RAG**","metadata":{}},{"cell_type":"code","source":"\n# Initialize the Gemini LLM for Generation\nfrom langchain_google_genai import ChatGoogleGenerativeAI\n\n# Create an instance of the Gemini LLM\nllm = ChatGoogleGenerativeAI(\n    model=GENERATION_MODEL,\n    temperature=0.3, # Lower temperature for more factual answers\n    #convert_system_message_to_human=True, # Helps manage prompts for some models\n    google_api_key=GOOGLE_API_KEY \n)\n\nprint(\"Gemini LLM for generation initialized.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.175758Z","iopub.execute_input":"2025-04-18T19:15:36.176048Z","iopub.status.idle":"2025-04-18T19:15:36.186347Z","shell.execute_reply.started":"2025-04-18T19:15:36.176026Z","shell.execute_reply":"2025-04-18T19:15:36.185377Z"}},"outputs":[{"name":"stdout","text":"Gemini LLM for generation initialized.\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"# Retrieval augmented generation (RAG) ","metadata":{}},{"cell_type":"code","source":"\n# Build the RAG Chain\nfrom langchain_core.prompts import ChatPromptTemplate\nfrom langchain.chains.combine_documents import create_stuff_documents_chain\nfrom langchain.chains import create_retrieval_chain\nfrom langchain_core.runnables import RunnablePassthrough\nfrom langchain_core.output_parsers import StrOutputParser\n\n# --- Create a Retriever ---\n# The retriever fetches relevant documents from the vector store based on the query.\nmy_retriever = vectorstore.as_retriever(\n    search_type=\"similarity\", # Other options: \"mmr\", \"similarity_score_threshold\"\n    search_kwargs={'k': 5} # Retrieve top 5 most relevant chunks\n)\nprint(\"Retriever created from vector store.\")\n\n# --- Define the Prompt Template ---\n# This template structures the input to the LLM, providing context and the question.\nRAG_PROMPT_TEMPLATE = \"\"\"\nCONTEXT:\n{context}\n\nQUESTION:\n{question}\n\nBased only on the context provided, answer the question. If the context doesn't contain the answer, state that you cannot answer based on the provided information.\n\"\"\"\n\nrag_prompt = ChatPromptTemplate.from_template(RAG_PROMPT_TEMPLATE)\nprint(\"RAG prompt template created.\")\n\n\n# --- Create the RAG Chain using LangChain Expression Language (LCEL) ---\n\n# This function formats the retrieved documents into a single string.\ndef format_docs(docs):\n    return \"\\n\\n\".join(doc.page_content for doc in docs)\n\n# Define the RAG pipeline\nrag_chain = (\n    # RunnablePassthrough assigns the original question to the 'question' key\n    # retriever | format_docs assigns the formatted context to the 'context' key\n    {\"context\": my_retriever | format_docs, \"question\": RunnablePassthrough()}\n    | rag_prompt  # Pass the dictionary to the prompt template\n    | llm         # Pass the formatted prompt to the LLM\n    | StrOutputParser() # Parse the LLM output into a string\n)\n\nprint(\"RAG chain created successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.187401Z","iopub.execute_input":"2025-04-18T19:15:36.187736Z","iopub.status.idle":"2025-04-18T19:15:36.313627Z","shell.execute_reply.started":"2025-04-18T19:15:36.187706Z","shell.execute_reply":"2025-04-18T19:15:36.312382Z"}},"outputs":[{"name":"stdout","text":"Retriever created from vector store.\nRAG prompt template created.\nRAG chain created successfully.\n","output_type":"stream"}],"execution_count":11},{"cell_type":"code","source":"# --- Function to ask a question ---\ndef car_manual_rag(query):\n    print(f\"\\n🤔 Query: {query}\")\n    try:\n        # Invoke the RAG chain\n        answer = rag_chain.invoke(query)\n        print(\"\\n✅ Answer:\")\n        print(answer)\n        return answer\n\n    except Exception as e:\n        print(f\"\\n❌ Error processing query: {e}\")\n\n#car_manual_rag(\"how to set seat heating?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.314716Z","iopub.execute_input":"2025-04-18T19:15:36.315064Z","iopub.status.idle":"2025-04-18T19:15:36.321554Z","shell.execute_reply.started":"2025-04-18T19:15:36.315031Z","shell.execute_reply":"2025-04-18T19:15:36.320431Z"}},"outputs":[],"execution_count":12},{"cell_type":"markdown","source":"# Grounding with Google","metadata":{}},{"cell_type":"code","source":"from IPython.display import display, Image, Markdown\n\nconfig_with_search = types.GenerateContentConfig(\n    tools=[types.Tool(google_search=types.GoogleSearch())],\n    temperature=0.0,\n)\n\ndef show_response(response):\n    for p in response.content.parts:\n        if p.text:\n            return p.text\n        elif p.inline_data:\n            return p.inline_data\n        else:\n            return p.to_json_dict()\n\ndef google_ground_search(query):\n    response = client.models.generate_content(\n        model='gemini-2.0-flash',\n        contents=query,\n        config=config_with_search,\n    )\n    rc = response.candidates[0]\n    return show_response(rc)\n\n#google_ground_search(\"how to do jump start in bmw x3?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.322630Z","iopub.execute_input":"2025-04-18T19:15:36.322972Z","iopub.status.idle":"2025-04-18T19:15:36.351056Z","shell.execute_reply.started":"2025-04-18T19:15:36.322935Z","shell.execute_reply":"2025-04-18T19:15:36.350020Z"}},"outputs":[],"execution_count":13},{"cell_type":"markdown","source":"# Agent\n","metadata":{}},{"cell_type":"code","source":"# Car Assistant Agent with RAG and Gemini Grounded Search using LangGraph\n# This notebook implements a car assistant that:\n# 1. First tries to answer using a RAG system with local knowledge\n# 2. Falls back to Gemini with Google Search grounding if RAG fails or returns \"I cannot answer\"\n\nimport os\nimport json\nfrom typing import Dict, List, Optional, Any, TypedDict, Annotated, Literal\nfrom dataclasses import dataclass\nimport chromadb\nfrom langchain.text_splitter import RecursiveCharacterTextSplitter\nfrom langchain.embeddings import HuggingFaceEmbeddings\nfrom langchain.vectorstores import Chroma\nfrom langchain.document_loaders import TextLoader, DirectoryLoader\nimport google.generativeai as genai\nfrom google.api_core import client_options as client_options_lib\nfrom google.generativeai import types\nfrom IPython.display import Markdown, display\nimport pandas as pd\n\n# LangGraph imports\nfrom langgraph.graph import StateGraph, END\nfrom langgraph.prebuilt import ToolNode\n#from langgraph.checkpoint import MemorySaver\nfrom typing import TypeVar\nfrom langgraph.pregel import Pregel\nfrom langgraph.graph.message import add_messages\nfrom pydantic import BaseModel, Field\n\n# Configuration for API keys\nimport dotenv\ndotenv.load_dotenv()\n\n# Set up Google API key\n#GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n#if not GOOGLE_API_KEY:\n#    raise ValueError(\"Please set GOOGLE_API_KEY in your environment variables or .env file\")\n\n# Set up Gemini configuration\ngenai.configure(api_key=GOOGLE_API_KEY)\n\n# Define the agent state\nclass AgentState(TypedDict):\n    \"\"\"State for the car assistant agent workflow.\"\"\"\n    question: str\n    rag_answer: Optional[str]\n    search_answer: Optional[str]\n    final_answer: Optional[str]\n    source: Optional[str]\n    should_use_search: bool\n    status: Literal[\"RUNNING\", \"DONE\"]\n\n# Define the fallback detection function\ndef should_use_search(rag_answer: Optional[str]) -> bool:\n    \"\"\"Determine if we should fall back to search based on the RAG answer.\"\"\"\n    if not rag_answer:\n        return True\n    \n    # List of exact phrases that indicate the RAG system couldn't provide a good answer\n    fallback_exact_phrases = [\n        \"i cannot answer based on the provided information\",\n        \"cannot answer based on the provided information\",\n        \"i don't have enough information\",\n        \"i do not have enough information\",\n        \"insufficient information\",\n        \"no information available\",\n        \"not found in the provided context\",\n        \"i don't know\",\n        \"i do not know\"\n    ]\n    \n    rag_answer_lower = rag_answer.lower()\n        \n    # Check for exact phrases (substring match)\n    for phrase in fallback_exact_phrases:\n        if phrase in rag_answer_lower:\n            return True\n            \n    # Additional checks for phrases indicating inability to answer\n    if \"cannot answer\" in rag_answer_lower or \"can't answer\" in rag_answer_lower:\n        return True\n        \n    if \"sorry\" in rag_answer_lower and (\"don't\" in rag_answer_lower or \"cannot\" in rag_answer_lower):\n        return True\n        \n    if \"unable to provide\" in rag_answer_lower or \"not able to provide\" in rag_answer_lower:\n        return True\n            \n    return False\n\n# Define tools\nclass CarTools:\n    \"\"\"Tools for the car assistant agent.\"\"\"\n    \n    @staticmethod\n    def car_manual_rag(question: str) -> str:\n        \"\"\"Tool to query the RAG system with car manual knowledge.\"\"\"\n        return car_manual_rag(question)\n\n    @staticmethod\n    def google(query: str) -> str:\n        \"\"\"Tool to use Gemini with Google Search grounding to answer queries.\"\"\"\n        return google_ground_search(query)\n\n    @staticmethod\n    def image_search(image_url: str) -> str:\n        \"\"\"\n        Tool to extract contents from an image based on the provided URL using the updated process_image function.\n        \"\"\"\n        print(f\"Processing image from URL: {image_url}\")\n        return process_image(image_url)  # Use the updated function\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.352283Z","iopub.execute_input":"2025-04-18T19:15:36.352621Z","iopub.status.idle":"2025-04-18T19:15:36.847246Z","shell.execute_reply.started":"2025-04-18T19:15:36.352596Z","shell.execute_reply":"2025-04-18T19:15:36.846185Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"\n# Define node functions\ndef process_question(state: AgentState) -> AgentState:\n    \"\"\"Process the initial question and query the RAG system.\"\"\"\n    question = state[\"question\"]\n    rag_answer = CarTools.car_manual_rag(question)\n    should_search = should_use_search(rag_answer)\n    \n    return {\n        **state,\n        \"rag_answer\": rag_answer,\n        \"should_use_search\": should_search\n    }\n\ndef route_by_answer_quality(state: AgentState) -> Literal[\"use_rag\", \"use_search\"]:\n    \"\"\"Route based on whether we should use RAG results or search.\"\"\"\n    if state[\"should_use_search\"]:\n        return \"use_search\"\n    else:\n        return \"use_rag\"\n\ndef use_rag_answer(state: AgentState) -> AgentState:\n    \"\"\"Use the RAG answer as the final answer.\"\"\"\n    return {\n        **state, \n        \"final_answer\": state[\"rag_answer\"],\n        \"source\": \"Car Manual - RAG\",\n        \"status\": \"DONE\"\n    }\n\ndef use_search_answer(state: AgentState) -> AgentState:\n    \"\"\"Use Google Search with Gemini to get an answer.\"\"\"\n    search_answer = CarTools.google(state[\"question\"])\n    return {\n        **state,\n        \"search_answer\": search_answer,\n        \"final_answer\": search_answer,\n        \"source\": \"Gemini with Google Search Grounding\",\n        \"status\": \"DONE\"\n    }\n\n# Update the process_image_state function to return both image contents and search results\ndef process_image_state(state: AgentState) -> AgentState:\n    \"\"\"\n    Processes an image URL, retrieves its description, and combines results\n    for nearest gas stations and car service stations based on detected content.\n    \"\"\"\n    image_url = state[\"question\"]  # Assuming the question contains the image URL\n    image_content = CarTools.image_search(image_url)  # Process the image URL\n\n    # Initialize variables for results\n    combined_result = f\"Image Contents: {image_content}\\n\\n\"\n\n    # Check for \"Low Fuel\" in image contents\n    if \"Low Fuel\" in image_content:\n        gas_station_result = CarTools.google(\"Nearby gas stations in New York City\")\n        combined_result += f\"Nearest Gas Stations: {gas_station_result}\\n\\n\"\n\n    # Check for \"Warning Light\" in image contents\n    if \"warning light\" in image_content:\n        car_service_result = CarTools.google(\"Nearby car service stations in New York City\")\n        combined_result += f\"Nearest Car Service Stations: {car_service_result}\\n\\n\"\n\n    return {\n        **state,\n        \"search_answer\": combined_result,  # Combined result with both gas stations and service centers\n        \"final_answer\": combined_result,  # Final response includes all data\n        \"source\": \"Image Search + Google Search\",\n        \"status\": \"DONE\"\n    }\n    ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.848473Z","iopub.execute_input":"2025-04-18T19:15:36.849184Z","iopub.status.idle":"2025-04-18T19:15:36.861522Z","shell.execute_reply.started":"2025-04-18T19:15:36.849157Z","shell.execute_reply":"2025-04-18T19:15:36.860383Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"\n# Build the LangGraph\ndef build_car_assistant_graph():\n    \"\"\"Build the LangGraph for the car assistant.\"\"\"\n    # Initialize the graph\n    workflow = StateGraph(AgentState)\n    \n    # Add nodes\n    workflow.add_node(\"process_question\", process_question)\n    workflow.add_node(\"process_image\", process_image_state)  # Updated node\n    workflow.add_node(\"use_rag_answer\", use_rag_answer)\n    workflow.add_node(\"use_search_answer\", use_search_answer)\n    workflow.add_node(\"route_by_answer_quality\", route_by_answer_quality)\n    \n    # Add edges\n    workflow.add_conditional_edges(\n        \"process_question\",\n        route_by_answer_quality,\n        {\n            \"use_rag\": \"use_rag_answer\",\n            \"use_search\": \"use_search_answer\"\n        }\n    )\n    \n    # Add an edge for image processing\n    workflow.add_edge(\"process_image\", END)\n    \n    # Add edges to end the graph\n    workflow.add_edge(\"use_rag_answer\", END)\n    workflow.add_edge(\"use_search_answer\", END)\n    \n    # Set the entry point\n    workflow.set_entry_point(\"process_question\")\n    \n    return workflow.compile()\n\n# Create the car assistant using LangGraph\ncar_assistant_graph = build_car_assistant_graph()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.862867Z","iopub.execute_input":"2025-04-18T19:15:36.863138Z","iopub.status.idle":"2025-04-18T19:15:36.896706Z","shell.execute_reply.started":"2025-04-18T19:15:36.863116Z","shell.execute_reply":"2025-04-18T19:15:36.895676Z"}},"outputs":[],"execution_count":16},{"cell_type":"markdown","source":"# Function Calling","metadata":{}},{"cell_type":"code","source":"\n# Function to run the car assistant and display results\ndef run_car_assistant(question: str, is_image: bool = False):\n    \"\"\"Run the car assistant for a given question or image URL and display the results.\"\"\"\n    # Initialize the state\n    state = {\n        \"question\": question,\n        \"rag_answer\": None,\n        \"search_answer\": None,\n        \"final_answer\": None,\n        \"source\": None,\n        \"should_use_search\": False,\n        \"status\": \"RUNNING\"\n    }\n    \n    if is_image:\n        # Use the process_image_state directly for image URLs\n        result = process_image_state(state)\n    else:\n        # Run the graph for text-based questions\n        result = car_assistant_graph.invoke(state)\n    \n    # Display the result\n    display(Markdown(f\"## Answer\\n{result['final_answer']}\"))\n    print(f\"Source: {result['source']}\")\n    return result\n\ndef smart_auto_assist_image(image_url):\n    print(\"\\n=== Car Assistant with Image ===\\n\")\n    \n    # Example questions and image URLs to test\n    example_inputs = [(image_url, True)]\n    \n    # Testing the assistant with example inputs\n    for i, (input_data, is_image) in enumerate(example_inputs, 1):\n        print(f\"\\n{'='*80}\\nInput {i}: {input_data}\\n{'='*80}\")\n        result = run_car_assistant(input_data, is_image=is_image)\n\n\ndef smart_auto_assist_chat(query):\n    print(\"\\n=== Car Assistant with Chat ===\\n\")\n    \n    # Example questions and image URLs to test\n    example_inputs = [\n        (query, False)\n    ]\n    \n    # Testing the assistant with example inputs\n    for i, (input_data, is_image) in enumerate(example_inputs, 1):\n        print(f\"\\n{'='*80}\\nInput {i}: {input_data}\\n{'='*80}\")\n        result = run_car_assistant(input_data, is_image=is_image)\n        \n\n# Interactive mode for custom questions\ndef interactive_mode():\n    while True:\n        question = input(\"\\nAsk a car-related question (or type 'exit' to quit): \")\n        if question.lower() == 'exit':\n            break\n        run_car_assistant(question)\n\n# Uncomment the next line to enter interactive mode\n# interactive_mode()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.898302Z","iopub.execute_input":"2025-04-18T19:15:36.898681Z","iopub.status.idle":"2025-04-18T19:15:36.917097Z","shell.execute_reply.started":"2025-04-18T19:15:36.898647Z","shell.execute_reply":"2025-04-18T19:15:36.915908Z"}},"outputs":[],"execution_count":17},{"cell_type":"markdown","source":"# Testing\n\n## **UseCase: 1 - Chat with car manual (RAG)** ","metadata":{}},{"cell_type":"code","source":"smart_auto_assist_chat(\"where to find VIN?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:36.918194Z","iopub.execute_input":"2025-04-18T19:15:36.918502Z","iopub.status.idle":"2025-04-18T19:15:37.732185Z","shell.execute_reply.started":"2025-04-18T19:15:36.918473Z","shell.execute_reply":"2025-04-18T19:15:37.731198Z"}},"outputs":[{"name":"stdout","text":"\n=== Car Assistant with Chat ===\n\n\n================================================================================\nInput 1: where to find VIN?\n================================================================================\n\n🤔 Query: where to find VIN?\n\n✅ Answer:\nThe VIN is located in the engine compartment, on the right-hand side of the vehicle.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"## Answer\nThe VIN is located in the engine compartment, on the right-hand side of the vehicle."},"metadata":{}},{"name":"stdout","text":"Source: Car Manual - RAG\n","output_type":"stream"}],"execution_count":18},{"cell_type":"markdown","source":"## **UseCase: 2 - Chat with Google - If RAG has no Answer**","metadata":{}},{"cell_type":"code","source":"smart_auto_assist_chat(\"what is the difference between AWD and FWD?\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:37.733424Z","iopub.execute_input":"2025-04-18T19:15:37.733738Z","iopub.status.idle":"2025-04-18T19:15:42.703830Z","shell.execute_reply.started":"2025-04-18T19:15:37.733714Z","shell.execute_reply":"2025-04-18T19:15:42.702803Z"}},"outputs":[{"name":"stdout","text":"\n=== Car Assistant with Chat ===\n\n\n================================================================================\nInput 1: what is the difference between AWD and FWD?\n================================================================================\n\n🤔 Query: what is the difference between AWD and FWD?\n\n✅ Answer:\nI cannot answer based on the provided information.  The text mentions all-wheel drive (AWD) and its benefit of improved drive power, but it does not explain the difference between AWD and front-wheel drive (FWD).\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"## Answer\nThe key difference between All-Wheel Drive (AWD) and Front-Wheel Drive (FWD) lies in which wheels receive power from the engine:\n\n*   **FWD (Front-Wheel Drive):** The engine sends power only to the front wheels.\n*   **AWD (All-Wheel Drive):** The engine sends power to all four wheels.\n\nHere's a more detailed breakdown:\n\n**FWD (Front-Wheel Drive)**\n\n*   **How it works:** The engine's power is directed to the front wheels, which are responsible for both propelling the vehicle and steering.\n*   **Benefits:**\n    *   Generally more fuel-efficient due to lighter weight and fewer components.\n    *   Lower production costs, often resulting in a lower purchase price.\n    *   Predictable handling in most normal driving conditions.\n*   **Cons:**\n    *   Less traction than AWD, especially in slippery conditions.\n    *   The front wheels can experience \"torque steer\" (a pulling sensation) during hard acceleration.\n\n**AWD (All-Wheel Drive)**\n\n*   **How it works:** The engine sends power to all four wheels. There are different types of AWD systems:\n    *   **Full-time AWD:** Power is constantly supplied to all four wheels.\n    *   **Part-time AWD:** The system primarily operates in two-wheel drive (usually FWD) and automatically engages all four wheels when it detects a loss of traction.\n*   **Benefits:**\n    *   Enhanced traction, providing better grip on slippery surfaces like snow, ice, and wet roads.\n    *   Improved acceleration and stability, especially when cornering.\n    *   Superior performance in light off-road situations.\n*   **Cons:**\n    *   Generally less fuel-efficient than FWD due to added weight and complexity.\n    *   Higher purchase price and potentially higher maintenance costs.\n    *   Can sometimes reduce legroom due to the placement of transmission components.\n\n**Which is better?**\n\n*   **FWD:** Best for drivers who prioritize fuel efficiency, affordability, and live in areas with mild weather conditions.\n*   **AWD:** Best for drivers who need maximum traction and stability, especially those who live in areas with harsh weather (snow, ice, rain) or who occasionally drive on unpaved roads.\n"},"metadata":{}},{"name":"stdout","text":"Source: Gemini with Google Search Grounding\n","output_type":"stream"}],"execution_count":19},{"cell_type":"markdown","source":"# **Testing - Image Analysis - Upload dashboard image**\n\n**Sample Image:** ","metadata":{}},{"cell_type":"markdown","source":"![](https://raw.githubusercontent.com/argowthamkumar/kaggle/refs/heads/main/capstone/images/low_fuel.jpg)","metadata":{}},{"cell_type":"code","source":"smart_auto_assist_image(\"https://raw.githubusercontent.com/argowthamkumar/kaggle/refs/heads/main/capstone/images/low_fuel.jpg\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T19:15:42.704923Z","iopub.execute_input":"2025-04-18T19:15:42.705239Z","iopub.status.idle":"2025-04-18T19:15:52.685918Z","shell.execute_reply.started":"2025-04-18T19:15:42.705211Z","shell.execute_reply":"2025-04-18T19:15:52.684434Z"}},"outputs":[{"name":"stdout","text":"\n=== Car Assistant with Image ===\n\n\n================================================================================\nInput 1: https://raw.githubusercontent.com/argowthamkumar/kaggle/refs/heads/main/capstone/images/low_fuel.jpg\n================================================================================\nProcessing image from URL: https://raw.githubusercontent.com/argowthamkumar/kaggle/refs/heads/main/capstone/images/low_fuel.jpg\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"## Answer\nImage Contents: Here's a description of the image contents:\n\nThe image shows the dashboard of a car. There are two main gauges:\n\n*   **Left Gauge:** Displays the engine's RPM (revolutions per minute) in thousands. The needle indicates a little over 1000 RPM. There is also a temperature gauge, which reads as slightly cold.\n*   **Right Gauge:** Displays the vehicle's speed in kilometers per hour (km/h). The needle is at approximately 20 km/h. Additionally, a fuel gauge indicates the fuel level is very low.\n\nIn the center of the dashboard, between the gauges, there is a digital display showing:\n\n*   A \"Low Fuel\" warning message with a fuel pump icon\n*   The transmission is in \"Drive\" (D)\n*   The outside temperature is -1 degrees Celsius.\n*   The car has traveled 1041 km.\n\nThere are several warning lights illuminated on the dashboard:\n\n*   Oil Pressure Warning Light: **HIGH**\n*   Battery Warning Light: **HIGH**\n*   Seatbelt Warning Light: **MEDIUM**\n*   Check Engine Light: **MEDIUM**\n*   Tire Pressure Warning Light: **MEDIUM**\n\nNearest Gas Stations: Okay, I can help you find nearby gas stations in New York City. To give you the most relevant results, I need to know your current location within New York City.\n\nHowever, I can provide you with some general information and options:\n\n**General Options for Finding Gas Stations:**\n\n*   **Use Online Search Engines/Apps:** Use online search engines such as Google, DuckDuckGo, or Maps. Many of these have the functionality to search for \"gas stations near me\".\n*   **Use Gas Station Finder Apps/Websites:** There are specific apps and websites designed to locate gas stations and compare prices, such as GasBuddy, and Way.\n*   **Check Specific Gas Station Websites:** You can use the Exxon Mobil Fuel Finder to find Exxon and Mobil stations. Also, you can find Sunoco stations.\n\n**Some Gas Stations Listed in New York, NY:**\n\n*   **Shell:** Brooklyn (98 3rd Ave)\n*   **BP:** Brooklyn (677 Kent Ave)\n*   **Mobil:** Manhattan (51-63 8th Ave)\n*   **Sunoco:** 5080 Broadway, New York, NY 10034\n\nTo get the most accurate results, I recommend using one of the methods above and providing your specific location in New York City.\n\n\nNearest Car Service Stations: Okay, I can help you find car service stations in New York City. Here are a few options, based on the search results:\n\n**AAA Approved Auto Repair Facilities** (Note: You may need a AAA membership)\n\n*   **Pica's Automotive Service:** 90 NJ-139, Jersey City, NJ 07310\n*   **Audi Brooklyn:** 700 Hicks St, Brooklyn, NY 11231\n*   **Centro Auto Body and Repair:** 334 Hoboken Ave, Jersey City, NJ 07306\n*   **Urban Classics Auto Repair:** 56 Kosciuszko St, Brooklyn, NY 11205\n*   **West Side Tire & Auto:** 236 West Side Ave, Jersey City, NJ 07305\n\n**Other Options Listed**\n\n*   **2020 Auto Service Corp:** 2315 12th Ave, New York, NY 10027\n*   **Manhattan Auto Repair Inc:** 552 W 48th St, New York, NY 10036\n*   **Manhattan Alignment & Diagnostic Center:** 555 W 131st Street, New York, NY 10027 (specializing in foreign and domestic automobiles as well as hybrids)\n*   **Luxury Auto Service:** 711 11th Ave, New York, NY 10019 (specializing in exotic car repairs)\n\n**Goodyear Service Centers / Warren Tire Service Centers** (Primarily Upstate NY)\n\nKeep in mind that \"nearby\" is relative to your current location within New York City. To get the most accurate results, I recommend performing a search on Google Maps or a similar service, as I don't have access to your precise location.\n\n\n"},"metadata":{}},{"name":"stdout","text":"Source: Image Search + Google Search\n","output_type":"stream"}],"execution_count":20}]}